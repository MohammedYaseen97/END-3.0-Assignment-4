{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END3 Session 4 Task 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedYaseen97/END3.0-Assignment-4/blob/main/END3_Session_4_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPhj6gnAnT2"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwn4oStE6PzV"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DLJ86m56Xdn",
        "outputId": "52afd42a-5e8b-4876-c8c5-1cee3ceccd84"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXTWwqXA6rP2",
        "outputId": "3fe76bfb-5ab2-4385-b192-39b1d4cd0083"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Karloff', 'and', 'Lugosi', '-', 'Together', 'again', '!', 'This', 'is', 'one', 'of', 'those', 'films', 'that', 'casual', 'fans', 'will', 'pass', 'over', 'and', 'tend', 'not', 'to', 'appreciate', 'as', 'much', '.', 'It', \"'s\", 'not', 'an', 'all', '-', 'out', 'horror', 'film', 'like', 'the', 'duo', \"'s\", 'previous', 'two', 'hits', ',', 'The', 'Black', 'Cat', 'and', 'The', 'Raven', '.', 'But', ',', 'it', 'is', 'very', 'worthy', 'of', 'both', \"'s\", 'talents', 'and', 'is', 'a', 'fun', 'film', 'when', 're', '-', 'visited.<br', '/><br', '/>The', 'Invisible', 'Ray', 'was', 'directed', 'by', 'Lambert', 'Hillyer', ',', 'a', 'director', 'who', 'mainly', 'made', 'westerns', ',', 'but', 'curiously', 'in', 'these', 'final', 'days', 'of', 'the', 'Laemmles', \"'\", 'reign', 'at', 'Universal', ',', 'he', 'found', 'himself', 'helming', 'this', 'and', 'the', 'Laemmles', \"'\", 'final', 'horror', 'film', ',', 'Dracula', \"'s\", 'Daughter', '.', 'Both', 'are', 'crisp', ',', 'clean', '-', 'cut', 'fantasies', 'that', 'are', 'very', 'light', 'on', 'horror', 'content', 'despite', 'the', 'fantastic', 'elements.<br', '/><br', '/>Just', 'as', 'Lugosi', 'went', 'wild', 'in', 'The', 'Raven', ',', 'much', 'needs', 'to', 'be', 'said', 'of', 'Karloff', \"'s\", 'hamming', 'in', 'The', 'Invisible', 'Ray', '.', 'The', 'one', 'aspect', 'of', 'the', 'story', 'that', 'is', 'particularly', 'unsatisfying', 'is', 'that', 'Karloff', \"'s\", 'character', ',', 'Rukh', ',', 'acts', 'so', 'madly', 'before', 'he', 'is', 'poisoned', 'by', 'Radium', 'X', ',', 'that', 'there', 'really', 'is', \"n't\", 'much', 'of', 'a', 'change', 'once', 'he', 'starts', 'glowing', '.', 'This', 'is', 'very', 'similar', 'to', 'the', 'complaint', 'people', 'have', 'about', 'Jack', 'Nicholson', 'in', 'The', 'Shining', '-', 'He', \"'s\", 'basically', 'a', 'loony', 'right', 'from', 'the', 'start', '.', 'There', 'is', \"n't\", 'any', 'real', 'transformation', '.', 'Same', 'here', '.', 'Halfway', 'through', 'Karloff', 'simply', 'has', 'an', 'added', 'purpose', 'for', 'revenge', 'in', 'his', 'mind', '.', 'I', 'still', 'enjoyed', 'his', 'performance', ',', 'though', ',', 'just', 'as', 'I', 'did', 'Lugosi', \"'s\", 'over', '-', 'the', '-', 'top', 'antics', 'in', 'The', 'Raven.<br', '/><br', '/>Meanwhile', ',', 'Lugosi', 'completely', 'surprises', 'you', 'and', 'gives', 'a', 'restrained', ',', 'and', 'thoughtful', 'turn', 'as', 'Rukh', \"'s\", 'rival', 'in', 'science', ',', 'Dr.', 'Benet', '.', 'Lugosi', 'also', 'has', 'some', 'of', 'the', 'best', 'lines', 'in', 'the', 'film', ',', 'including', 'a', 'memorable', 'warning', 'to', 'the', 'police', 'trying', 'to', 'catch', 'Rukh', ',', 'of', 'which', 'I', 'am', 'in', 'alignment', 'with', 'horror', 'film', 'writer', 'John', 'Soister', 'on', '-', '\"', 'And', 'if', 'he', '(', 'Rukh', ')', 'touches', 'anyone', '?', '\"', 'the', 'inspector', 'inquires', '.', 'Lugosi', 'hesitatingly', 'replies', ',', 'in', 'a', 'way', 'that', 'only', 'Lugosi', 'could', 'deliver', ',', '\"', 'They', 'die', '\"', '.', 'Just', 'as', 'Lugosi', 'could', 'be', 'so', 'off', ',', 'he', 'could', 'also', 'be', 'more', 'perfect', 'than', 'any', 'actor', '.', 'This', 'is', 'one', 'of', 'those', 'moments.<br', '/><br', '/>Therefore', ',', 'Karloff', 'and', 'Lugosi', \"'s\", 'interactions', 'are', 'all', 'very', 'good', 'as', 'we', 'get', 'the', 'mad', 'antics', 'of', 'Karloff', 'pared', 'off', 'against', 'the', 'cool', 'logic', 'of', 'Lugosi', '.', 'Karloff', 'would', 'go', 'on', 'to', 'play', 'similar', 'mad', 'scientists', 'many', 'times', ',', 'however', ',', 'one', 'wishes', 'Lugosi', 'would', 'have', 'gotten', 'to', 'play', 'more', 'straight', 'roles', 'like', 'this', 'one', '.', 'He', 'only', 'had', 'one', 'more', 'chance', '(', 'Ninotchka).<br', '/><br', '/>The', 'Invisible', 'Ray', 'is', 'a', 'fun', 'film', ',', 'and', 'a', 'real', 'treat', 'to', 'the', 'true', 'Karloff', 'and', 'Lugosi', 'fans', '.', 'It', 'is', 'one', 'of', 'those', 'films', 'that', 'improves', 'on', 'each', 'viewing', ',', 'not', 'because', 'it', 'is', 'a', 'masterpiece', ',', 'but', 'because', 'of', 'the', 'charisma', 'and', 'talent', 'of', 'its', \"'\", 'stars', 'and', 'how', 'this', 'story', 'complements', 'the', 'darker', ',', 'more', 'horrific', 'pairings', 'they', 'had', '.', 'The', 'special', 'effects', ',', 'by', 'the', 'always', 'innovative', 'John', 'Fulton', ',', 'are', 'terrific', 'and', 'the', 'supporting', 'actors', 'are', 'all', 'adequate', '.', 'Frances', 'Drake', 'looks', 'as', 'beautiful', 'as', 'she', 'did', 'in', 'Mad', 'Love', 'and', 'plays', 'a', 'strong', 'woman', ',', 'something', 'seldom', 'seen', 'in', 'classic', 'horror', 'films', '.', 'The', 'scene', 'in', 'the', 'end', 'when', 'Karloff', 'stalks', 'her', 'and', 'she', 'does', \"n't\", 'scream', 'is', 'one', 'of', 'the', 'most', 'haunting', 'moments', 'of', 'the', 'film', '.', 'A', 'terrific', ',', 'fun', 'film', '!'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HMVqiZd6tR0"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOeQ6KpP7M-0",
        "outputId": "f0290e04-2b1d-401e-8a36-631153c2bb64"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixkM1jQ7TB-"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD4SFKnc7g0D",
        "outputId": "299f06a2-7ff6-4ee9-bfa0-d15bdc0d1c8b"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttKvFTCQ7isK",
        "outputId": "3b867128-0d03-4c68-a7d7-b1ebd9dfc6a0"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 201060), (',', 190719), ('.', 164664), ('and', 108716), ('a', 108322), ('of', 100243), ('to', 92800), ('is', 75991), ('in', 60740), ('I', 53971), ('it', 53155), ('that', 48824), ('\"', 43776), (\"'s\", 42921), ('this', 42221), ('-', 36846), ('/><br', 35231), ('was', 34752), ('as', 30023), ('with', 29736)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZXIsIV47mlI",
        "outputId": "22d914de-de05-4900-d0c1-52b670a87a5e"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbx3T9-7x4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40a890c-7ae6-4701-f28d-3dc5346cca4b"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3gBfP6mEJ_0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZQQV1-ELZf"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0_X5kSwENad"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdGb8dKBEO2x",
        "outputId": "e947c4dc-5f33-4c07-b9e8-916ee0f28ed6"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,867,049 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAeEtXiJEQCj"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Utp4-qAERRG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyAXf58FESdL"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4yNiGXQETh9"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1iGJW1wEUrL"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNQxQS3tEWUW"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVM8MtV6EYIw"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5KZmM4EZXW",
        "outputId": "6f26ff54-1f3a-4263-d3b3-a11cd686c1f2"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.44%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 49.19%\n",
            "Epoch: 02 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.42%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.37%\n",
            "Epoch: 03 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.47%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.17%\n",
            "Epoch: 04 | Epoch Time: 1m 11s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.44%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.23%\n",
            "Epoch: 05 | Epoch Time: 1m 10s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.37%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIiKAJMaEbKO",
        "outputId": "8a706a68-9aa2-4ac1-96cd-849ffaf7b250"
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.691 | Test Acc: 55.45%\n"
          ]
        }
      ]
    }
  ]
}